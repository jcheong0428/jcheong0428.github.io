---
layout: page
title: Research
permalink: /research/
order: 3
---

---
<p></p>
# Areas of Interest
I am interested in understanding why people do the things they do and think the way they think.
More specifically, I build computational models that explain and predict people's behaviors, thoughts, and interpersonal outcomes during social interactions and group decision-making settings. I use methods from psychophysiology (skin conductance, heart rate), neuroimaging (fMRI, intracranial EEG), and facial expressions extracted from face videos to complement experimental behavioral data to augment our understanding of human behaviors and judgments in social contexts. With these broad goals and interests, I have led and participated in a number of projects described below.

1. Impact of shared experiences on social connection.
Why is is that we often feel more connected to another person after we watched a movie together, shared a meal together, or took a same bus ride together? To answer this questions, we recorded videos of participants's facial expressions while they watched a TV show either alone or with another participant for four hours. We found that when participants engage in a shared experience with another person, they are more likely to emote than when they watched alone and also more likely to emote at similar times. Most importantly, participants reported developing stronger feelings of connection towards each other when they displayed more synchronized facial expressions in time. To a lesser extent, we also found that similarities in how people emote with different configurations of their facial muscles and how they think about the characters in the show also contribute to building social rapport. Overall, this research suggests temporal and spatial facial expression synchrony metrics could potentially be used as a valuable metric to gauge social connection between individuals that could help design better face-to-face social interaction platforms or organizational activities.

2. Understanding how groups make decisions together.
Research on group decision making often studies how accurate group decisions are compared to individuals' when there is a right or wrong answer. However, real life decisions often don't have clear right or wrong answers and are often determined based on individuals values (e.g. education, family, environment) and preferences (e.g. food tastes, music tastes). I developed a novel group decision making paradigm to study how individuals' values and preferences are revealed, modified, and integrated in group settings. We compare different models to find the one that best explains the data while using facial expressions and pose data extracted from video clips recorded while the individuals negotiate their perspectives to understand the non-verbal cues and signals indicative of each person's role, influence, and satisfaction with the group decisions.

3. Building facial expression models of complex and social emotions.
There are many more facets to emotions than joy, anger, sadness, disgust, surprise, and fear, such as regret, guilt, pain, and empathy. Using decision making paradigms with real outcomes such as painful thermal stimulations applied to oneself or to others, we elicited these emotions in a controlled lab environment while measuring their facial expressions. Using features extracted from the temporal dynamics of facial expressions, we were able to build models that predict such emotions as well as how they might be perceived by others. These work provide potential avenues to study the role of emotion in complex social interactions and how they guide future behavior and judgments of others.

In the process, I have authored and contributed to research tools that may also be useful to others.

#### [FaceSync](https://github.com/jcheong0428/facesync)  
Python toolbox to synchronize videos based on audio.

#### [FEAT (Facial Expression Analysis Toolbox)](https://github.com/cosanlab/feat)
Python toolbox for streamlined analysis of facial expression data.

#### [Affectiva-API-APP](https://github.com/cosanlab/affectiva-api-app)
Web tool to extract facial expressions from videos using Affectiva's JavaScript API.

#### [PaperWiki](https://paperwiki.herokuapp.com/)
Free online summaries for scientific articles, created and edited by readers around the world.

#### [nltools](https://github.com/ljchang/nltools)
Python toolbox designed for streamlined analysis of neuroimaging data.

#### [pyMedoc](https://github.com/cosanlab/pymedoc)
Python class to remotely communicate with Medoc Pathway Thermode over WiFi.
